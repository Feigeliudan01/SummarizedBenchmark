---
title: "Case Study: Single-Cell RNA-Seq Simulation"
author: "Patrick K. Kimes, Alejandro Reyes"
date: "`r BiocStyle::doc_date()`"
package: "`r BiocStyle::pkg_ver('SummarizedBenchmark')`"
abstract: >
  "In this vignette, we illustrate a simple approach to using the *SummarizedBenchmark* framework for organizing benchmarks with complex outputs, i.e. when methods return non-vector-like objects. This approach is demonstrated with a comparison of simulation methods implemented in the `r BiocStyle::Biocpkg("splatter")` package. SummarizedBenchmark package version: `r packageVersion("SummarizedBenchmark")`"
output:
  BiocStyle::html_document:
    highlight: pygments
    toc: true
    fig_width: 5
vignette: >
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{Case Study: Single-Cell RNA-Seq Simulation}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r echo=FALSE, include=FALSE}
knitr::opts_chunk$set(tidy = FALSE,
                      cache = TRUE,
                      dev = "png",
                      message = FALSE,
                      error = FALSE,
                      warning = TRUE)
```

# Introduction

Simulated data sets, where the ground truth is known, are often used for developing and comparing computational tools. However, the methods for simulating data often take a backseat to the methods being compared using the simulated data. Recognizing this problem, the `r BiocStyle::Biocpkg("splatter")` package implements several "simulators" for single-cell mRNA sequencing (scRNA-seq) data using a uniform API. Namely, given a set of simulation parameters, each method returns a _SingleCellExperiment_ object of simulated counts. 

Using comparisons presented in paper describing the `r BiocStyle::Biocpkg("splatter")` package (_Zappia et al., 2017_), we illustrate how the _SummarizedBenchmark_ framework can be used to perform comparisons when the output of each method is more complex than a vector of numbers (e.g. a _SingleCellExperiment_).

# Building the BenchDesign

```{r}
library("SummarizedBenchmark")
library("magrittr")
```

Parameters for the simulators implemented in `r BiocStyle::Biocpkg("splatter")` can either be manually specified or estimated using existing data. Here, we use RSEM counts for the subset of high coverage samples in the `fluidigm` data set included in the `r BiocStyle::Biocpkg("scRNAseq")` package. The data is made available as a _SummarizedExperiment_ object.

```{r}
library("splatter")
library("scRNAseq")

data("fluidigm")
se <- fluidigm[, colData(fluidigm)[, "Coverage_Type"] == "High"]
assays(se) <- assays(se)["rsem_counts"]
assayNames(se) <- "counts"
```

To make comparing the simulated data sets with the original `fluidigm` data easier, we convert the object to the _SingleCellExperiment_ class.

```{r}
sce <- as(se, "SingleCellExperiment")
```

Each of the simulators in the `r BiocStyle::Biocpkg("splatter")` package follow the `[prefix]Simulate` naming convention, with the corresponding parameter estimation function, `[prefix]Estimate`. Here, we use four methods included in the comparisons of _Zappia et al. (2017)_.

```{r}
bd <- BenchDesign() %>%
    addBMethod("splat", splatSimulate,
               params = splatEstimate(in_data), dropout.present = FALSE,
               verbose = in_verbose, seed = in_seed,
               bpost = list) %>% 
    addBMethod("splat.drop", splatSimulate,
               params = splatEstimate(in_data), dropout.present = TRUE, 
               verbose = in_verbose, seed = in_seed,
               bpost = list) %>% 
    addBMethod("simple", simpleSimulate,
               params = simpleEstimate(in_data),
               verbose = in_verbose, seed = in_seed, 
               bpost = list) %>%
    addBMethod("lun", lunSimulate,
               params = lunEstimate(in_data),
               verbose = in_verbose, seed = in_seed,
               bpost = list)
```

Each simulator returns a single _SingleCellExperiment_ object containing the simulated scRNA-seq counts. However, to fit the _SummarizedBenchmark_ structure, each method in the _BenchDesign_ must return a vector or a list. To handle the non-standard output of the methods, we add `bpost = list` in each `addBMethod` call to wrap each _SingleCellExperiment_ object in a list. 

Using the `"counts"` assay of the `fluidigm` data set as input, we generate simulated data with the four methods.

```{r}
sb <- bd %>%
    buildBench(list(in_data = assay(sce, "counts"),
                    in_verbose = FALSE,
                    in_seed = 19120128))
sb
```

The simulated data sets are returned as a single row in the assay of the _SummarizedBenchmark_ object, with each column containing a list with a single _SingleCellExperiment_ object.

```{r}
assay(sb)
sapply(assay(sb), class)
```

Now that we have our set of simulated data sets, we can compare the behavior of each simulator. Fortunately, the `r BiocStyle::Biocpkg("splatter")` package includes two useful functions for comparing _SingleCellExperiment_ objects (`compareSCEs` and `diffSCEs`). The assay of the _SummarizedBenchmark_ can be passed directly to these functions. Here, we concatenate the original data set, `sce`, with the simulated data sets for comparison.

```{r}
res_compare <- compareSCEs(c(ref = sce, assay(sb)[1, ]))
res_diff <- diffSCEs(c(ref = sce, assay(sb)[1, ]), ref = "ref")
```

While these functions produce several metrics and plots, we only include two for illustration. More details on the output of these functions can be found in the documentation of the `r BiocStyle::Biocpkg("splatter")` package.

```{r}
res_compare$Plots$MeanVar

res_diff$Plots$MeanVar
```

While, conveniently, functions already existed for comparing the simulated data sets, we can also define them separately using the _SummarizedBenchmark_ framework using `addPerformanceMetrics()`. We illustrate this feature using the "zeros per cell" and "zeros per gene" metrics shown in Figure 3 of _Zappia et al. (2016)_. Since the metric for each method is a vector (e.g. of zeros per cell) and not a single value, we again using `list` to wrap the output in the `evalFunction`. 

```{r}
sb <- sb %>%
    addPerformanceMetric(
        assay = "bench",
        evalMetric = "zerosPerCell",
        evalFunction = function(query, truth) {
            list(colMeans(assay(query[[1]], "counts") == 0))
        }) %>%
    addPerformanceMetric(
        assay = "bench",
        evalMetric = "zerosPerGene",
        evalFunction = function(query, truth) {
            list(rowMeans(assay(query[[1]], "counts") == 0))
        })
```

The metrics are calculated using `estimatePerformanceMetrics`. For plotting, we only keep the `blabel`, `value`, and `performanceMetric` columns of the returned table

```{r}
sbmets <- estimatePerformanceMetrics(sb, tidy = TRUE)
sbmets  <- dplyr::select(sbmets, blabel, value, performanceMetric)
head(sbmets)
```

Notice that the `value` is a list for each method and metric. These vectors can be expanded using `tidyr::unnest`.

```{r}
sbmets <- tidyr::unnest(sbmets)
head(sbmets)
```

These metrics can now be explored using standard plotting functions.

```{r}
ggplot(sbmets, aes(x = blabel, y = value,
                   color = blabel, fill = blabel)) +
    geom_boxplot(alpha = 1/2) +
    xlab("method") +
    scale_color_discrete("method") + 
    facet_grid(performanceMetric ~ .) +
    theme_bw()
```

An advantage of the _SummarizedBenchmark_ framework is that rerunning the comparisons with a new data set is as simple as calling `buildBench` with the same BenchDesign object paired with new `data =` input. To illustrate this, we run the same simulators, but with simulation parameters estimated using the example single-cell count data included with the `r BiocStyle::Biocpkg("scater")` package.

```{r}
data(sc_example_counts, package = "scater")
scec <- SingleCellExperiment(assays = list(counts = sc_example_counts))

buildBench(bd, 
           data = list(in_data = scec,
                       in_verbose = FALSE,
                       in_seed = 19120128))
```

# References

- [Zappia L, Phipson B, Oshlack A. 2017. Splatter: Simulation Of Single-Cell RNA Sequencing Data. Genome Biology. (doi:10.1186/s13059-017-1305-0)](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-017-1305-0)
